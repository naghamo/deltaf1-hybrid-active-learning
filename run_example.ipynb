{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-19T15:27:06.827796360Z",
     "start_time": "2025-09-19T15:26:04.152723492Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/deltaf1-hybrid-active-learning/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:27:08.586249702Z",
     "start_time": "2025-09-19T15:27:06.830962497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "1ee195758ca57c80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:27:09.061296277Z",
     "start_time": "2025-09-19T15:27:09.008642175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cfg = ExperimentConfig(\n",
    "    seed=42,\n",
    "    total_rounds=5,\n",
    "    experiment_name=\"dummy_test_pipeline\",\n",
    "    save_dir=Path(\"./experiments\"),\n",
    "\n",
    "    # Pool settings\n",
    "    initial_pool_size=200,\n",
    "    acquisition_batch_size=256,\n",
    "\n",
    "    # Model\n",
    "    model_name_or_path=\"distilbert-base-uncased\",\n",
    "    num_labels=4, # TODO: maybe make it figure it out on its own based on dataset\n",
    "    tokenizer_kwargs={\n",
    "        \"max_length\": 128,\n",
    "        \"padding\": \"max_length\",\n",
    "        \"truncation\": True,\n",
    "        \"add_special_tokens\": True,\n",
    "        \"return_tensors\": \"pt\"\n",
    "    },\n",
    "\n",
    "    # Dataset names (for reference)\n",
    "    data=\"agnews\",\n",
    "\n",
    "    # Strategy\n",
    "    strategy_class=\"DeltaF1Strategy\",\n",
    "    strategy_kwargs={\"epsilon\": 0.01, \"k\": 2}, # The base params are passed internally, only strategy specific params needed here\n",
    "\n",
    "    optimizer_class = \"Adam\",\n",
    "    optimizer_kwargs = {\"lr\": 1e-3, \"weight_decay\": 1e-4},\n",
    "\n",
    "    criterion_class = \"CrossEntropyLoss\",\n",
    "    criterion_kwargs = {},\n",
    "\n",
    "    scheduler_class = \"StepLR\",\n",
    "    scheduler_kwargs = {\"step_size\": 10, \"gamma\": 0.1},\n",
    "\n",
    "    # Sampler\n",
    "    sampler_class=\"RandomSampler\",\n",
    "    sampler_kwargs={\"seed\": 42},\n",
    "    # sampler_class=\"EntropySampler\",\n",
    "    # sampler_kwargs={\"show_progress\": True},\n",
    "\n",
    "    # Training\n",
    "    device=device,\n",
    "    epochs=3,\n",
    "    batch_size=64\n",
    ")"
   ],
   "id": "cb57004dfbea90ca",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T15:27:14.103982235Z",
     "start_time": "2025-09-19T15:27:09.061973163Z"
    }
   },
   "cell_type": "code",
   "source": "al = ActiveLearning(cfg)",
   "id": "c15c6ebae79dba52",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading tokenizer and model from 'distilbert-base-uncased'...\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m al \u001B[38;5;241m=\u001B[39m \u001B[43mActiveLearning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/deltaf1-hybrid-active-learning/adaptive_al_v2/active_learning.py:34\u001B[0m, in \u001B[0;36mActiveLearning.__init__\u001B[0;34m(self, cfg)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, cfg: ExperimentConfig):\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg \u001B[38;5;241m=\u001B[39m cfg\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/deltaf1-hybrid-active-learning/adaptive_al_v2/active_learning.py:42\u001B[0m, in \u001B[0;36mActiveLearning._initialize\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_seeds(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mseed)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize_model_and_tokenizer()\n\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize_pool()\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize_classes()\n",
      "File \u001B[0;32m~/deltaf1-hybrid-active-learning/adaptive_al_v2/active_learning.py:59\u001B[0m, in \u001B[0;36mActiveLearning._initialize_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_initialize_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     58\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Initialize datasets\"\"\"\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_dataset, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_dataset, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     logging\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m     61\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_dataset)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Validation size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_dataset)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_dataset)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/deltaf1-hybrid-active-learning/adaptive_al_v2/active_learning.py:137\u001B[0m, in \u001B[0;36mActiveLearning._load_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    134\u001B[0m dataset_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# Make sure the index is reset, or we need to change the pool initialization\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m train_dataset, val_dataset, test_dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28meval\u001B[39m(\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mload_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m(path=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, seed=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mseed\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, model_name_or_path=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mmodel_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, tokenizer_kwargs=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mtokenizer_kwargs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m train_dataset, val_dataset, test_dataset\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Just checking if it actually works",
   "id": "8af4dc97750a51d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Initial pool stats: {al.pool.get_pool_stats()}\")",
   "id": "8485b7bb611031dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "round_stats = al.train_one_round(new_indices=None)\n",
    "print(f\"Round 1 completed. Val F1: {round_stats['f1_score']:.4f}, Training Time: {round_stats['training_time']:.2f}s\")"
   ],
   "id": "24d4cec80a9aa879",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "new_indices = al.sample_next_batch()\n",
    "print(f\"Sampled {len(new_indices)} new indices: {new_indices[:5]} ...\")"
   ],
   "id": "d4114fb6e0f50bc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "round_stats = al.train_one_round(new_indices=new_indices)\n",
    "print(f\"Round 2 completed. Val F1: {round_stats['f1_score']:.4f}, Training Time: {round_stats['training_time']:.2f}s\")"
   ],
   "id": "f5d16592aea125e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_additional_rounds = 3\n",
    "for r in range(num_additional_rounds):\n",
    "    print(f\"\\n--- Round {al.current_round + 1}\")\n",
    "\n",
    "    new_indices = al.sample_next_batch()\n",
    "    if not new_indices:\n",
    "        print(\"No more unlabeled data available!\")\n",
    "        break\n",
    "\n",
    "    round_stats = al.train_one_round(new_indices=new_indices)\n",
    "    print(f\"Val F1: {round_stats['f1_score']:.4f}, Training Time: {round_stats['training_time']:.2f}s\")\n",
    "    print(f\"Pool Stats: {round_stats['pool_stats']}\")"
   ],
   "id": "46d363e465beebb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FULL PIPELINE HERE ! ! !",
   "id": "5989786f4babe408"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final_metrics = al.run_full_pipeline()\n",
    "print(f\"Final Test Metrics: F1={final_metrics['f1_score']:.4f}, Accuracy={final_metrics['accuracy']:.4f}, Loss={final_metrics['loss']:.4f}\")"
   ],
   "id": "b2976e59fc9195f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "al.save_experiment()",
   "id": "474893112e83c0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(r\"experiments/dummy_test_pipeline/results_20250829_171203.json\", 'r') as f:\n",
    "    experiment_data = json.load(f)"
   ],
   "id": "94843c8c0ccce73f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(experiment_data.keys())",
   "id": "b4221facf5bc88e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "experiment_data['cfg']",
   "id": "63253569c2715cd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "experiment_data['total_rounds']",
   "id": "2e45af560a7164f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "experiment_data['round_val_stats'][-1]",
   "id": "bd769b5d17ffa236",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "experiment_data[\"final_pool_stats\"]",
   "id": "1ae22899026cd37d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "experiment_data[\"final_test_stats\"]",
   "id": "f3ff7f1ae7f58d9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "485a0c36ff2d07c5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
