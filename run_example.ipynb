{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:48.838635Z",
     "start_time": "2025-08-22T13:43:48.834635Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "\n",
    "from adaptive_al_v2.strategies import FineTuneStrategy\n",
    "from adaptive_al_v2.samplers import RandomSampler\n",
    "from adaptive_al_v2.config import ExperimentConfig\n",
    "\n",
    "from adaptive_al_v2 import ActiveLearning\n",
    "\n",
    "from adaptive_al_v2.utils.data_loader import load_agnews\n",
    "from adaptive_al_v2.utils.text_datasets import SimpleTextDataset\n",
    "from adaptive_al_v2.utils.text_classifiers import SimpleTextClassifier # Dummy class for testing"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading necessary model + optimizer/criterion/scheduler",
   "id": "feaeec202a6c13ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:50.390979Z",
     "start_time": "2025-08-22T13:43:49.696558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SimpleTextClassifier(\n",
    "    hidden_dim=32,\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Model: {model}\")"
   ],
   "id": "1ee195758ca57c80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model: SimpleTextClassifier(\n",
      "  (fc1): Linear(in_features=3, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the data (maybe we should abstract this instead)",
   "id": "42c5f7ecf732c51b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:51.329640Z",
     "start_time": "2025-08-22T13:43:51.062481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train, df_val, df_test = load_agnews(path='data')\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SimpleTextDataset(\n",
    "    texts=df_train['text'].tolist(),\n",
    "    labels=df_train['label'].tolist()\n",
    ")\n",
    "\n",
    "val_dataset = SimpleTextDataset(\n",
    "    texts=df_val['text'].tolist(),\n",
    "    labels=df_val['label'].tolist()\n",
    ")\n",
    "\n",
    "test_dataset = SimpleTextDataset(\n",
    "    texts=df_test['text'].tolist(),\n",
    "    labels=df_test['label'].tolist()\n",
    ")"
   ],
   "id": "cb57004dfbea90ca",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating a configuration for the active learning",
   "id": "2789672f189c40e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:52.235679Z",
     "start_time": "2025-08-22T13:43:52.231239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cfg = ExperimentConfig(\n",
    "    seed=42,\n",
    "    experiment_name=\"dummy test!!!\",\n",
    "    save_dir=Path(\"./experiments\"),\n",
    "\n",
    "    # Active learning settings\n",
    "    initial_pool_size=100,\n",
    "    batch_size=32,\n",
    "\n",
    "    # Model configuration\n",
    "    model_class=SimpleTextClassifier,\n",
    "    model_kwargs={\n",
    "        \"hidden_dim\": 32,\n",
    "        \"num_classes\": 4\n",
    "    },\n",
    "\n",
    "    train_dataset = train_dataset,\n",
    "    val_dataset = val_dataset,\n",
    "    test_dataset = test_dataset,\n",
    "\n",
    "    # Strategy and sampler instances\n",
    "    strategy=FineTuneStrategy(\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        epochs=3,\n",
    "        batch_size=32\n",
    "    ),\n",
    "\n",
    "    sampler=RandomSampler(seed=42)\n",
    ")"
   ],
   "id": "2e1f7a2ae226fa57",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:52.686816Z",
     "start_time": "2025-08-22T13:43:52.683080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Strategy: {cfg.strategy}\")\n",
    "print(f\"Sampler: {cfg.sampler}\")\n",
    "print(f\"Model class: {cfg.model_class}\")"
   ],
   "id": "5e3599e742f41bd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: <adaptive_al_v2.strategies.fine_tuning_strategy.FineTuneStrategy object at 0x0000021066A1F550>\n",
      "Sampler: <adaptive_al_v2.samplers.random_sampler.RandomSampler object at 0x0000021064BF8910>\n",
      "Model class: <class 'adaptive_al_v2.utils.text_classifiers.SimpleTextClassifier'>\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:53.126099Z",
     "start_time": "2025-08-22T13:43:53.114256Z"
    }
   },
   "cell_type": "code",
   "source": "al = ActiveLearning(cfg)",
   "id": "f5d16592aea125e7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:53.618899Z",
     "start_time": "2025-08-22T13:43:53.615220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Dataset sizes:\")\n",
    "print(f\"Train: {len(al.train_dataset)}\")\n",
    "print(f\"Val: {len(al.val_dataset)}\")\n",
    "print(f\"Test: {len(al.test_dataset)}\")"
   ],
   "id": "46d363e465beebb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "Train: 108000\n",
      "Val: 12000\n",
      "Test: 7600\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:54.821141Z",
     "start_time": "2025-08-22T13:43:54.817281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pool_stats = al.pool.get_pool_stats()\n",
    "print(f\"Initial pool stats: {pool_stats}\")"
   ],
   "id": "b2976e59fc9195f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial pool stats: {'labeled_count': 100, 'unlabeled_count': 107900, 'total_count': 108000}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:55.252246Z",
     "start_time": "2025-08-22T13:43:55.241212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test dataset access\n",
    "sample = al.train_dataset[0]\n",
    "print(f\"Dataset sample: {sample[0][:50]}... | Label: {sample[1]}\")\n",
    "\n",
    "# Test pool subsets\n",
    "labeled_subset = al.pool.get_labeled_subset()\n",
    "unlabeled_subset = al.pool.get_unlabeled_subset()\n",
    "print(f\"Pool subsets - Labeled: {len(labeled_subset)}, Unlabeled: {len(unlabeled_subset)}\")\n",
    "\n",
    "# Test DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(labeled_subset, batch_size=8, shuffle=True)\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch {i+1}: {len(inputs)} inputs, targets shape: {targets.shape}\")\n",
    "    print(f\"Sample input: {inputs[0][:30]}...\")\n",
    "    print(f\"Sample targets: {targets[:3].tolist()}\")\n",
    "    break"
   ],
   "id": "474893112e83c0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sample: tensor([283.,  54., 218.])... | Label: 1\n",
      "Pool subsets - Labeled: 100, Unlabeled: 107900\n",
      "Batch 1: 8 inputs, targets shape: torch.Size([8])\n",
      "Sample input: tensor([185.,  35., 138.])...\n",
      "Sample targets: [2, 2, 0]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:55.851005Z",
     "start_time": "2025-08-22T13:43:55.712845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train with initial labeled data\n",
    "round_stats = al.train_one_round(new_indices=None)\n",
    "print(f\"Initial training completed!\")\n",
    "print(f\"Round stats: {round_stats}\")"
   ],
   "id": "301aeb9cf9fdea5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training completed!\n",
      "Round stats: {'training_time': 0.13252997398376465, 'avg_loss': 41.456451098124184, 'epochs': 3, 'total_samples': 100, 'new_samples': 0, 'f1_score': 0.7291267979503492, 'pool_stats': {'labeled_count': 100, 'unlabeled_count': 107900, 'total_count': 108000}}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:56.902358Z",
     "start_time": "2025-08-22T13:43:56.897057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample new indices\n",
    "new_indices = al.sample_next_batch(batch_size=20)\n",
    "print(f\"Sampling completed!\")\n",
    "print(f\"Sampled {len(new_indices)} new indices: {new_indices[:5]}...\")\n",
    "\n",
    "# Check updated pool stats\n",
    "updated_stats = al.pool.get_pool_stats()\n",
    "print(f\"Updated pool stats: {updated_stats}\")"
   ],
   "id": "baaa4e7b0c618b11",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using provided batch size 20 instead of 32 in config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling completed!\n",
      "Sampled 20 new indices: [21441, 60650, 49788, 35420, 83965]...\n",
      "Updated pool stats: {'labeled_count': 100, 'unlabeled_count': 107900, 'total_count': 108000}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:57.751914Z",
     "start_time": "2025-08-22T13:43:57.733315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train with newly sampled data\n",
    "round_stats = al.train_one_round(new_indices=new_indices)\n",
    "print(f\"Training with new samples completed!\")\n",
    "print(f\"Round stats: {round_stats}\")"
   ],
   "id": "5391e817b6d6ef25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with new samples completed!\n",
      "Round stats: {'training_time': 0.016015291213989258, 'avg_loss': 41.140060106913246, 'epochs': 3, 'total_samples': 120, 'new_samples': 20, 'f1_score': 0.06618860521154724, 'pool_stats': {'labeled_count': 120, 'unlabeled_count': 107880, 'total_count': 108000}}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The active learning training rounds (maybe we should also abstract this further)",
   "id": "b19e847ff8584b7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:43:58.924273Z",
     "start_time": "2025-08-22T13:43:58.860249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_rounds = 3\n",
    "for round_num in range(num_rounds):\n",
    "    print(f\"\\n--- Round {round_num + 3}\")  # Continue from previous rounds\n",
    "\n",
    "    # Sample new batch\n",
    "    new_indices = al.sample_next_batch(batch_size=15)\n",
    "    print(f\"Sampled {len(new_indices)} new samples\")\n",
    "\n",
    "    if len(new_indices) == 0:\n",
    "        print(\"No more unlabeled data!\")\n",
    "        break\n",
    "\n",
    "    # Train with new samples\n",
    "    round_stats = al.train_one_round(new_indices=new_indices)\n",
    "    print(f\"F1 Score: {round_stats['f1_score']:.4f}\")\n",
    "    print(f\"Training Time: {round_stats['training_time']:.2f}s\")\n",
    "    print(f\"Pool Stats: {round_stats['pool_stats']}\")\n",
    "\n",
    "print(f\"\\nMultiple rounds completed successfully!\")"
   ],
   "id": "b51128216dbe4d0c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using provided batch size 15 instead of 32 in config.\n",
      "WARNING:root:Using provided batch size 15 instead of 32 in config.\n",
      "WARNING:root:Using provided batch size 15 instead of 32 in config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Round 3\n",
      "Sampled 15 new samples\n",
      "F1 Score: 0.5390\n",
      "Training Time: 0.02s\n",
      "Pool Stats: {'labeled_count': 135, 'unlabeled_count': 107865, 'total_count': 108000}\n",
      "\n",
      "--- Round 4\n",
      "Sampled 15 new samples\n",
      "F1 Score: 0.6274\n",
      "Training Time: 0.02s\n",
      "Pool Stats: {'labeled_count': 150, 'unlabeled_count': 107850, 'total_count': 108000}\n",
      "\n",
      "--- Round 5\n",
      "Sampled 15 new samples\n",
      "F1 Score: 0.1146\n",
      "Training Time: 0.02s\n",
      "Pool Stats: {'labeled_count': 165, 'unlabeled_count': 107835, 'total_count': 108000}\n",
      "\n",
      "Multiple rounds completed successfully!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:07.554834Z",
     "start_time": "2025-08-22T13:44:07.551429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get experiment summary\n",
    "summary = al.get_experiment_summary()\n",
    "print(f\"Experiment summary generated!\")\n",
    "print(f\"Total rounds: {summary['total_rounds']}\")\n",
    "print(f\"Final F1: {summary['final_f1']:.4f}\")\n",
    "print(f\"Final pool stats: {summary['final_pool_stats']}\")"
   ],
   "id": "3e0671a0294073a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment summary generated!\n",
      "Total rounds: 5\n",
      "Final F1: 0.1146\n",
      "Final pool stats: {'labeled_count': 165, 'unlabeled_count': 107835, 'total_count': 108000}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T13:44:09.770868Z",
     "start_time": "2025-08-22T13:44:09.766759Z"
    }
   },
   "cell_type": "code",
   "source": "al.save_experiment()",
   "id": "57da63e5ece8dd24",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T21:13:59.296059Z",
     "start_time": "2025-08-17T21:13:59.294047Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ac77489a1f6ec589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "94843c8c0ccce73f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
